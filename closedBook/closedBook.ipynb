{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Exact Match Accuracy (OpenAI GPT-3.5): 0.33\n",
      "Exact Match Accuracy (LLaMA 2 via LangChain): 0.11\n",
      "Exact Match Accuracy (LLaMA 3 via LangChain): 0.20\n",
      "Exact Match Accuracy (GPT-2): 0.00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from openai import OpenAI\n",
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "# OpenAI API Configuration\n",
    "OPENAI_API_KEY = \"addkey\"\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Load the NQ-Open dataset from Hugging Face\n",
    "splits = {\"validation\": \"nq_open/validation-00000-of-00001.parquet\"}  # Define the validation split file\n",
    "df_validation = pd.read_parquet(\"hf://datasets/google-research-datasets/nq_open/\" + splits[\"validation\"])\n",
    "\n",
    "# Extract questions and answers\n",
    "questions = df_validation[\"question\"].tolist()\n",
    "answers = df_validation[\"answer\"].tolist()\n",
    "\n",
    "# Load GPT-2\n",
    "model_gpt2 = \"gpt2\"\n",
    "tokenizer_gpt2 = AutoTokenizer.from_pretrained(model_gpt2)\n",
    "model_gpt2 = AutoModelForCausalLM.from_pretrained(model_gpt2)\n",
    "gpt2_pipeline = pipeline(\"text-generation\", model=model_gpt2, tokenizer=tokenizer_gpt2)\n",
    "\n",
    "# Initialize LangChain models for Ollama and DeepSeek\n",
    "llm_llama2 = ChatOllama(model=\"llama2\", temperature=0)\n",
    "llm_llama3 = ChatOllama(model=\"llama3.2\", temperature=0)\n",
    "llm_deepseek = ChatOllama(model=\"deepseek-r1\", temperature=0)\n",
    "\n",
    "def answer_question_openai(question):\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": f\"{question}? Answer concisely in one or two words only with no punctuation.\"}\n",
    "        ],\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "    )\n",
    "    return chat_completion.choices[0].message.content.strip()\n",
    "\n",
    "def answer_question_llama2(question):\n",
    "    messages = [(\"human\", f\"{question}? Answer concisely in one or two words only with no punctuation.\")]\n",
    "    return llm_llama2.invoke(messages).content.strip()\n",
    "\n",
    "def answer_question_llama3(question):\n",
    "    messages = [(\"human\", f\"{question}? Answer concisely in one or two words only with no punctuation.\")]\n",
    "    return llm_llama3.invoke(messages).content.strip()\n",
    "\n",
    "def answer_question_deepseek(question):\n",
    "    messages = [(\"human\", f\"{question}? Answer in one or two words only with no punctiation.\")]\n",
    "    return llm_deepseek.invoke(messages).content.strip()\n",
    "\n",
    "def answer_question_gpt2(question):\n",
    "    prompt = f\"{question}? Answer in one or two words only with no punctiation.\"\n",
    "    response = gpt2_pipeline(prompt, max_length=50, truncation=True, pad_token_id=tokenizer_gpt2.eos_token_id)\n",
    "    return response[0]['generated_text'].split(\"Answer in one or two words only with no punctiation.\")[-1].strip()\n",
    "\n",
    "# Evaluate with Exact Match Score and Save Predictions\n",
    "def exact_match(pred, true):\n",
    "    return int(any(pred.strip().lower() == t.strip().lower() for t in true))\n",
    "\n",
    "def evaluate_and_save(model_name, model_func, n_samples=50):\n",
    "    results = []\n",
    "    correct = 0\n",
    "    for i in range(n_samples):\n",
    "        pred = model_func(questions[i])\n",
    "        is_correct = exact_match(pred, answers[i])\n",
    "        correct += is_correct\n",
    "        results.append({\n",
    "            \"question\": questions[i],\n",
    "            \"true_answers\": \", \".join(answers[i]),\n",
    "            \"predicted\": pred,\n",
    "            \"correct\": is_correct\n",
    "        })\n",
    "    accuracy = correct / n_samples\n",
    "    df_results = pd.DataFrame(results)\n",
    "    df_results.to_csv(f\"outputs/{model_name}_predictions.csv\", index=False)\n",
    "    return accuracy\n",
    "\n",
    "# Run Evaluation and Save Predictions\n",
    "nb_Samples = 1000\n",
    "accuracy_openai = evaluate_and_save(\"openai_gpt3.5\", answer_question_openai, nb_Samples)\n",
    "accuracy_llama2 = evaluate_and_save(\"llama2\", answer_question_llama2, nb_Samples)\n",
    "accuracy_llama3 = evaluate_and_save(\"llama3.2\", answer_question_llama3, nb_Samples)\n",
    "# accuracy_deepseek = evaluate_and_save(\"deepseek-r1\", answer_question_deepseek, nb_Samples)\n",
    "accuracy_gpt2 = evaluate_and_save(\"gpt2\", answer_question_gpt2, nb_Samples)\n",
    "\n",
    "print(\"Device set to use cpu\")\n",
    "print(f\"Exact Match Accuracy (OpenAI GPT-3.5): {accuracy_openai:.2f}\")\n",
    "print(f\"Exact Match Accuracy (LLaMA 2 via LangChain): {accuracy_llama2:.2f}\")\n",
    "print(f\"Exact Match Accuracy (LLaMA 3 via LangChain): {accuracy_llama3:.2f}\")\n",
    "# print(f\"Exact Match Accuracy (DeepSeek-R1 via LangChain): {accuracy_deepseek:.2f}\")\n",
    "print(f\"Exact Match Accuracy (GPT-2): {accuracy_gpt2:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyserini",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
